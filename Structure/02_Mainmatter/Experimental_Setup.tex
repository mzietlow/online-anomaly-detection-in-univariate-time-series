\section{Experimental Setup}\label{sect:experimental-setup}
In this section, details on the dataset \cref{subsect:datasets} and the selection
of algorithms \cref{subsect:algorithm-overview} are given.

\subsection{Datasets}\label{subsect:datasets}
The algorithms evaluated in this paper are compared on a variety of synthetic
and real-world univariate time series, taken from the \gls{nab}-collection.
While the \gls{nab} datasets were chosen for this paper, a selection of additional
univariate datasets is given in \cref{tab:univariate-datasets}.
Additional multivariate datasets are given in \cref{tab:multivariate-datasets}.

In this subsection, the recent controversy surrounding several anomaly detection datasets
will be discussed. Further, \gls{nab} and its metric will be introduced, also a
short visual examination is performed.

\subsubsection{Controversy}
Recent research inspired by~\cite{Nakamura.2020} has raised doubts about the
adequacy of multiple anomaly detection datasets~\cite{Renjie.2020}. Prominently
included are Yahoo!S5, \gls{nab}, NASA~\cite{Hundman.2018}, and OMNI~\cite{Su.2019}
datasets.

It is objected that these datasets suffer from one or multiple of the following
flaws~\cite{Renjie.2020}:
\begin{description}
    \item[Triviality] A dataset is considered trivial if it can be \textit{solved}
    by a simple combination of statistical operations such as \textit{mean},
    \textit{max}, \textit{std}, \textit{diff}.
    
    Examples that demonstrate this flaw are taken mainly from the Yahoo!S5 dataset
    for which also a code listing of a brute force approach is provided. Three
    time series from OMNI are examined and only a single one from \gls{nab}.
    
    For NASA, \textcite{Renjie.2020} claim that about 90\% of included anomalies
    are trivial and show \(>10\) examples. For OMNI, 50\% are claimed to be trial,
    but only three examples are given. For \gls{nab}, the authors claim that
    \textit{most} time series are trivial, but omit evidence by giving only a
    single example.

    \item[Unrealistic Density] A dataset is considered unrealistically dense, if
    either
    \begin{enumerate*}[a.)]
        \item a large portion (e.g.\ \(> 0.33\)) of observations are labeled anomalous,
        \item many (e.g.\ \(> 5\)) proximal regions are marked as separate anomalies,
        \item separate anomalies are proximal (e.g.\ \textit{sandwiching} a single
        normal observation)~\cite[cf.][]{Renjie.2020}.
    \end{enumerate*}

    Examples that demonstrate this flaw are taken from Yahoo!S5 and NASA\@.

    \item[Mislabeled Ground Truth] A dataset is mislabeled if its labels contain
    any false negatives or false positives.

    Examples that demonstrate this flaw are taken mainly from Yahoo!S5. A single
    time series from \gls{nab} is given.

    \item[Run-to-failure Bias] A dataset suffers from the run-to-failure bias if
    anomalies appear only towards its end without normal observations following
    them.

    Examples that demonstrate this flaw are taken from Yahoo!S5 and NASA\@.
\end{description}

In summary, the majority of flaws are to be found within Yahoo!S5 and NASA datasets.
From~\cite{Renjie.2020} it can be concluded that
\textbf{Anomaly detection is a visual domain and researchers are responsible for
providing not just scores, but visual examination of their results.}
While the authors do not to provide evidence for the triviality of \gls{nab},
this conclusion holds here as well.

As a side note, \textcite{Renjie.2020} mention the creation of a novel benchmark
dataset. Unfortunately, its release is still delayed.

\subsubsection{Numenta Anomaly Benchmark}
The \acrfull{nab} was created as a compilation of 11 synthetic and 47 real,
domain specific time series. Of the 11 synthetic time series, 5 do not contain
anomalous values. The time series consist of both a timestamp and a single
numeric value (see \defref{def:observation}) and contain between 1000--22.000 such
observations. The complete benchmark contains a total of 365.551 observations~\cite{Lavin.2015}.

The time series (except for the \textit{realKnownCause}-subset) were labeled
according to a unified procedure~\cite{Numenta.2015} by a team of
multiple researchers. It was released in October 2015, as a reaction to the lack
of publicly available benchmarks for univariate anomaly detection~\cite{Lavin.2015}
(although by that time the Yahoo!S5 benchmark had already been released).

The upcoming paragraph describes the scoring function introduced with \gls{nab}.
This is followed (in vein of~\cite{Renjie.2020}) by a short visual examination
of the dataset.

\paragraph{Numenta Anomaly Metric}
Numenta~\cite{Lavin.2015} defines a custom scoring function.\ They choose to do
so rather than using F-Score~\cite[183]{Murphy.2012} or similar well-known metric,
because ``traditional scoring methods [\dots] do not incorporate time and do not
reward early detection [and are therefore] not applicable to [real-time anomaly detection]''~\cite{Lavin.2015}.

The metric is defined using \textit{anomaly windows}.
\begin{definition}[Anomaly Window]\label{def:anomaly-window}
    An anomaly window is a set of two timestamps (in other words a \textit{timerange}),
    centered around an anomalous point~\cite[cf.][]{Lavin.2015}. All points inside
    this window are considered anomalous. An example of this is shown in \cref{fig:anomaly-window}.
    Window length is defined per time series as:
    \[\frac{\text{len}(\text{time series}) * 0.1}{\text{number of anomalies}\in \text{time series}}\]
    \begin{figure}[htp!]
        \centering
        \includegraphics[width=.6\textwidth]{anomaly_windows.png}
        \caption[Example of an \defref{def:anomaly-window}.]{Example of an \defref{def:anomaly-window}. Illustration
        by the author.}\label{fig:anomaly-window}
    \end{figure}
\end{definition}
If multiple detections exist within a window, only the first detection is scored.
Additional detections within the window are ignored~\cite[cf.][]{Lavin.2015}.
Detections earlier in the window give higher positive scores than later detections.
Detections outside the anomaly window give negative scores.

Details on calculation of the scoring function are given in \cref{app:numenta-score}
and an exemplary application is depicted in \cref{fig:anomaly-score-example}.


\paragraph{Visual Examination}
In this paragraph, an overview of the most common anomaly types within \gls{nab}
is given. From visual observation only, the vast majority (about 30) of time
series from the dataset contain point anomalies~\cref{fig:point-anomalies-nab}.
Other more common types include contextual anomalies \cref{fig:contextual-anomalies-nab}.
Collective anomalies only appear in form of change points. A very good example
for collective anomalies however, as the one from \cref{fig:collective-anomalies-nab},
is not found within \gls{nab}.

Regarding triviality allegations from \textcite{Lavin.2015}, \(\sim 1/3\) of
point anomalies are so far from their neighborhood, that \(\mu_t + 3*\sigma_t\)
(\(\mu_t, \sigma_t\) are the moving mean and the moving standard deviation
respectively) would suffice to detect them, e.g.\ \cref{fig:point-anomalies-nab}.
This implies triviality of the dataset. However, such trivial solution would
also detect many false positives. While, from short examination, it appears possible
to solve many of the time series presented in \gls{nab} with comparatively simple
statistical operations, such a solution would probably require a unique set of such
operations for every time series. Thereby defeating the purpose of \gls{nab}:
scoring unified algorithms that must \textit{not} be adjusted for every such
time series.

Additional plots from the dataset can be found in \cref{sect:additonal-plots-dataset}.

\begin{figure}[htp!]
    \centering
    \begin{subfigure}[t]{.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{anomaly_types_examples/final/png/Twitter_volume_CRM.png}
    \end{subfigure}
    \begin{subfigure}[t]{.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{anomaly_types_examples/final/png/ec2_request_latency_system_failure.png}
    \end{subfigure}
    \caption[Two examples of Point Anomalies.]{Two examples of Point Anomalies. Illustrations by the author.}\label{fig:point-anomalies-nab}
\end{figure}

\begin{figure}[htp!]
    \centering
    \begin{subfigure}[t]{.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{anomaly_types_examples/final/png/art_daily_jumpsdown.png}
    \end{subfigure}
    \begin{subfigure}[t]{.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{anomaly_types_examples/final/png/art_daily_nojump.png}
    \end{subfigure}
    \caption[Two examples of (artificial) cyclicity violations (contextual anomalies).]{Two examples of (artificial) cyclicity violations (contextual anomalies). Illustrations by the author.}\label{fig:contextual-anomalies-nab}
\end{figure}

\begin{figure}[htp!]
    \centering
    \begin{subfigure}[t]{.49\linewidth}
        \centering
        \includegraphics[width=\textwidth]{anomaly_types_examples/final/png/grok_asg_anomaly.png}
    \end{subfigure}
    \caption[An example of two change points (collective anomalies)]{An example of two change points (collective anomalies) and a point anomaly. Illustrations by the author.}\label{fig:collective-anomalies-nab}
\end{figure}
\clearpage

\subsection{Algorithm overview}\label{subsect:algorithm-overview}
In an attempt to reduce the implementation complexity required for this paper,
the majority of algorithms has been adopted from open source libraries and
adjusted slightly for application to the \gls{nab}-dataset.\footnote{Customization most notably
included the partition of time series into multiple subsets that were alternatingly
used for training and inference.} On GitHub, several repositories can be found
which curate lists of such libraries. All repositories used for this process are
listed in \cref{tab:curation-lists}.

From these repositories, all libraries that offer algorithms belonging to either
\invdefref{def:forecasting-based-algo} or \invdefref{def:boundary-based-algo}
are listed in the appendix (forecasting-based: \cref{tab:forecasting-packages},
boundary-based: \cref{tab:boundary-packages}). Both tables contain three columns:
an (almost exhaustive) list of models offered by the library, the latest
released version, and the date of the latest commit.

Then, a subset of ten libraries is chosen. Five of them with a focus on forecasting
and the remaining five with a focus on boundaries. Libraries that are found within
another library are dropped from the list (e.g.\ \(\text{Prophet, GluonTS } \in \text{ AtsPy}\)).
Finally, a set of libraries is picked by the author, whereby recently updated libraries,
libraries with sufficient documentation and libraries with a high number of
stars (measuring to an extent the appreciation of the community) are slightly
preferred. The chosen libraries are presented in \cref{tab:chosen-packages}.

From these ten libraries, a subset of algorithms is selected. The selected
forecasting-algorithms are shown in \cref{tab:chosen-forecasting-algo},
boundary-algorithms are shown in \cref{tab:chosen-boundary-algo}.

If not stated otherwise, default parameters from within the libraries are adopted.
