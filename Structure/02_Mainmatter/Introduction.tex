\section{Introduction}
It is not new that companies are using an evergrowing set of computer systems
to keep their services online. Monitoring teams are challenged to identify, fix,
and prevent breakages to these systems. This involves analysis of continuous
streams of system-health data, made up of e.g.\ natural language logs, hits per
minute, or system loads like CPU and RAM\@. While breakages often manifest visibly
to the human spectator in the related system-health data, it is impossible to spectate
millions of data streams as often produced in larger companies~\cite[cf.][]{Zhu.2017}.

To alleviate this complexity, anomaly detection algorithms are introduced,
which automate the detection of such system issues. However, the domain of
anomaly detection is frequently evolving, and it is unclear, which algorithm to
choose.

In this paper, a number of algorithms is evaluated and compared using the
\gls{nab}-dataset, consisting of 58 time series~\cite{Lavin.2015}.

The paper is organized as follows. In \cref{sect:definitions}, definitions for
time series, anomalies and anomaly detection are found. In \cref{sect:experimental-setup},
the \gls{nab} metric and dataset are described and a recent controversy surrounding
\gls{nab} is discussed. Also, reasoning for algorithm-selection is given.
In \cref{sect:results-and-discussion}, the produced results are presented, discussed,
and recommendations on algorithm selection are given. Finally, in \cref{sect:conclusion}
the paper is wrapped up and recommendations on future work are given.